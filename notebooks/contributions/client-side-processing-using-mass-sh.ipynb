{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edc import print_info\n",
    "print_info(\"client-side-processing-using-mass-sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edc import setup_environment_variables\n",
    "setup_environment_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important notes\n",
    "This notebook requires:\n",
    "- AWS credentials -> for boto3 setup options see https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\n",
    "- S3 bucket (exposed as environment variable MY_AWS_BUCKET) -> for bucket configuration see https://docs.sentinel-hub.com/api/latest/#/BATCH_API/batch_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Side Processing using data prepared via EDC Mass Sentinel Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "import io\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# date & time\n",
    "import time\n",
    "from datetime import timezone, date, datetime\n",
    "from dateutil.relativedelta import relativedelta as rdelta\n",
    "from dateutil.rrule import rrule, MONTHLY\n",
    "\n",
    "# Oauth\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "from requests_oauthlib import OAuth2Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get authorization token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your client credentials\n",
    "client_id = %env SH_CLIENT_ID\n",
    "client_secret = %env SH_CLIENT_SECRET\n",
    "\n",
    "# Create a session\n",
    "client = BackendApplicationClient(client_id=client_id)\n",
    "oauth = OAuth2Session(client=client)\n",
    "\n",
    "token = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n",
    "                          client_id=client_id, client_secret=client_secret)\n",
    "\n",
    "resp = oauth.get(\"https://services.sentinel-hub.com/oauth/tokeninfo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Request\n",
    "Enter start and end date, input bands, indices. The resulting data cube will have two time intervals per month, being split at `day_of_new_interval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = date(2018,7,1) # Y,M,D\n",
    "enddate = date(2018,9,15)  # Y,M,D\n",
    "\n",
    "input_bands = [\"B03\",\n",
    "               \"B04\",\n",
    "               \"B05\",\n",
    "               \"B08\"]\n",
    "indices = ['NDVI',\n",
    "           \"NDWI\",\n",
    "           \"CVI\"]\n",
    "\n",
    "bucket_name = %env MY_AWS_BUCKET\n",
    "\n",
    "day_of_new_interval = 16 # leave this unchanged in most of the cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Data Cube Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "starttime = datetime(*startdate.timetuple()[:6])\n",
    "endtime = datetime(*enddate.timetuple()[:6])\n",
    "\n",
    "d=day_of_new_interval\n",
    "dates = list(rrule(MONTHLY, dtstart=startdate, until=enddate, bymonthday=[1,d-1,d,31]))\n",
    "dates = [starttime] + dates if dates[0] != starttime else dates\n",
    "dates = dates + [endtime] if dates[-1] != endtime else dates\n",
    "\n",
    "starts = dates[0::2]\n",
    "starts = [int(d.timestamp()) for d in starts] # timestamps for arithmetic\n",
    "ends   = [d+rdelta(hour=23, minute=59, second=59) for d in dates[1::2]]\n",
    "ends   = [int(d.timestamp()) for d in ends]   # timestamps for arithmetic\n",
    "avg_times = list(np.mean(list(zip(starts,ends)), axis=1))\n",
    "avg_times = [datetime.utcfromtimestamp(a) for a in avg_times]\n",
    "avg_times = [dt.isoformat() for dt in avg_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [\"SCL\", \"dataMask\"] # SCL ... Scene Classification Layer\n",
    "\n",
    "output_bands = input_bands + indices\n",
    "output_array =  [ { 'id': \"\\\"\" + ob + \"\\\"\", 'bands': len(avg_times), \"sampleType\": \"SampleType.UINT16\"} for ob in output_bands ]\n",
    "for oa in output_array:\n",
    "    if oa[\"id\"] == '\"CVI\"':\n",
    "        oa[\"sampleType\"] = \"SampleType.FLOAT32\"\n",
    "output_array = str(output_array).replace(\"'\", '')\n",
    "\n",
    "int_bands = '{' + ','.join([f'{ib}: []' for ib in input_bands]) + '}'\n",
    "results_object = '{' + ','.join([f'{ob}: []' for ob in output_bands]) + '}'\n",
    "debug_results = '{' + ','.join([f\"{output_bands[i]}: [{i+1}]\" for i in range(len(output_bands))]) + '}'\n",
    "responses = [{\"identifier\": ob,\"format\": {\"type\": \"image/tiff\"}} for ob in output_bands]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evalscript & the Request Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#double curly brackets render as single curly brackets in f-strings\n",
    "evalscript = f\"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "var debug = []\n",
    "\n",
    "var ic = {{  // index components\n",
    "  'NDVI':  [\"B08\", \"B04\"],\n",
    "  \"GNDVI\": [\"B08\", \"B03\"],\n",
    "  \"BNDVI\": [\"B08\", \"B02\"],\n",
    "  \"NDSI\":  [\"B11\", \"B12\"],\n",
    "  \"NDWI\":  [\"B03\", \"B08\"]\n",
    "}}\n",
    "\n",
    "function setup(ds) {{\n",
    "  return {{\n",
    "    input: [{{\n",
    "      bands: {str(input_bands + masks)}, \n",
    "      units: \"DN\"\n",
    "    }}],\n",
    "    output: {output_array},\n",
    "    mosaicking: Mosaicking.ORBIT       \n",
    "  }}\n",
    "}}\n",
    "\n",
    "function validate (sample) {{\n",
    "  if (sample.dataMask!=1) return false;\n",
    "  \n",
    "  var scl = Math.round(sample.SCL);\n",
    "  \n",
    "  if (scl === 3) {{ // SC_CLOUD_SHADOW\n",
    "    return false;\n",
    "  }} else if (scl === 9) {{ // SC_CLOUD_HIGH_PROBA\n",
    "    return false; \n",
    "  }} else if (scl === 8) {{ // SC_CLOUD_MEDIUM_PROBA\n",
    "    return false;\n",
    "  }} else if (scl === 7) {{ // SC_CLOUD_LOW_PROBA\n",
    "    //return false;\n",
    "  }} else if (scl === 10) {{ // SC_THIN_CIRRUS\n",
    "    return false;\n",
    "  }} else if (scl === 11) {{ // SC_SNOW_ICE\n",
    "    return false;\n",
    "  }} else if (scl === 1) {{ // SC_SATURATED_DEFECTIVE\n",
    "    return false;\n",
    "  }} else if (scl === 2) {{ // SC_DARK_FEATURE_SHADOW\n",
    "    //return false;\n",
    "  }}\n",
    "  return true;\n",
    "}}\n",
    "\n",
    "function calculateIndex(a,b)\n",
    "{{\n",
    "  if ((a+b)==0) return 0;\n",
    "  // stretch [-1,+1] to [0,1]\n",
    "  return ((a-b)/(a+b)+1)/2;\n",
    "}}\n",
    "\n",
    "function interpolatedValue(arr)\n",
    "{{\n",
    "  //here we define the function on how to define the proper value - e.g. linear interpolation; we will use average \n",
    "  if (arr.length==0) return 0;\n",
    "  if (arr.length==1) return arr[0];\n",
    "  var sum = 0;\n",
    "  for (j=0;j<arr.length;j++)\n",
    "  {{sum+=arr[j];}}\n",
    "  return Math.round(sum/arr.length);\n",
    "}}\n",
    "\n",
    "var results = {results_object}\n",
    "\n",
    "// We split each month into two halves. This will make it easier to append months to data cube later\n",
    "var day_of_new_interval = {day_of_new_interval}\n",
    "var endtime = new Date({datetime(*enddate.timetuple()[:3],23,59,59).timestamp()*1000}) // UNIX epoch in ms\n",
    "\n",
    "function evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata) {{\n",
    "  \n",
    "  //Debug part returning \"something\" if there are no  valid samples (no observations)\n",
    "  if (!samples.length)\n",
    "  return {debug_results}\n",
    "  \n",
    "  var is_in_last_half_of_month = endtime.getUTCDate() >= day_of_new_interval\n",
    "  var i = 0; // interval number\n",
    "  var int_bands = {int_bands}\n",
    "  \n",
    "  for (var j = 0; j < samples.length; j++) {{\n",
    "    \n",
    "    //TODO order should be reversed when we go leastRecent\n",
    "    \n",
    "    // if scene is outside of current half of month, fill result array and change half of month\n",
    "    // algorithm starts with most recent observation\n",
    "    if (( !is_in_last_half_of_month && scenes[j].date.getUTCDate() >= day_of_new_interval) ||\n",
    "    (  is_in_last_half_of_month && scenes[j].date.getUTCDate() <  day_of_new_interval))\n",
    "    {{\n",
    "      fillResultArray(i, int_bands)\n",
    "      \n",
    "      //reset values\n",
    "      for (var int_b in int_bands) {{\n",
    "        int_bands[int_b] = []\n",
    "      }}\n",
    "      \n",
    "      is_in_last_half_of_month = !is_in_last_half_of_month;\n",
    "      i++;\n",
    "    }}\n",
    "    \n",
    "    if (validate(samples[j]))\n",
    "    {{\n",
    "      // push input samples into their respective arrays\n",
    "      for (var int_b in int_bands) {{\n",
    "        int_bands[int_b].push(samples[j][int_b])\n",
    "      }}\n",
    "    }}\n",
    "    \n",
    "  }}\n",
    "  \n",
    "  //execute this for the last interval \n",
    "  fillResultArray(i, int_bands);\n",
    "  \n",
    "  return results\n",
    "}}\n",
    "\n",
    "function fillResultArray(i, int_bands)\n",
    "{{\n",
    "  for (var b in int_bands) {{\n",
    "    if(int_bands[b].length==0) results[b][i] = 0\n",
    "    else results[b][i] = interpolatedValue(int_bands[b])\n",
    "  }}\n",
    "  \n",
    "  for (var ix of {indices}) {{\n",
    "    if(ic.hasOwnProperty(ix)) {{\n",
    "      results[ix][i] = 65535*calculateIndex(\n",
    "        results[ic[ix][0]][i],\n",
    "        results[ic[ix][1]][i]\n",
    "      )\n",
    "    }}\n",
    "    if(ix===\"CVI\"){{\n",
    "      // output sample type for CVI is FLOAT32\n",
    "      results[ix][i] = results[\"B08\"][i]*results[\"B05\"][i] / (results[\"B03\"][i]*results[\"B03\"][i])\n",
    "    }}\n",
    "  }}\n",
    "}}\n",
    "\n",
    "function updateOutputMetadata(scenes, inputMetadata, outputMetadata) {{\n",
    "  outputMetadata.userData = {{\n",
    "    \"date_created\": Date(),\n",
    "    \"metadata\": scenes.map(s => {{\n",
    "      s.date = s.date.toString()\n",
    "      return s\n",
    "    }}),\n",
    "    \"time\" : {avg_times},\n",
    "    \"debug\": debug\n",
    "  }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "  \"processRequest\": {\n",
    "    \"input\": {\n",
    "      \"bounds\": {\n",
    "        \"properties\": {\n",
    "          \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n",
    "        },\n",
    "        \"bbox\": [16.446445736463346, 47.680841561177864, 16.49776618971013, 47.72587417451863]\n",
    "      },\n",
    "      \"data\": [\n",
    "        {\n",
    "          \"location\": \"AWS:eu-central-1\",\n",
    "          \"type\": \"S2L2A\",\n",
    "          \"dataFilter\": {\n",
    "            \"timeRange\": {\n",
    "              \"from\": starttime.isoformat() + 'Z',\n",
    "              \"to\": endtime.isoformat() + 'Z'\n",
    "            },\n",
    "            \"mosaickingOrder\": \"mostRecent\",\n",
    "            \"maxCloudCoverage\": 100,\n",
    "            \"previewMode\": \"DETAIL\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"output\": {\n",
    "      \"responses\": [*responses]\n",
    "    },\n",
    "    \"evalscript\": evalscript\n",
    "  },\n",
    "  \"tilingGridId\": 0,\n",
    "  \"bucketName\": bucket_name,\n",
    "  \"resolution\": 60.0,\n",
    "  \"description\": \"Test Loipersbach\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "  #'Accept': 'application/tar'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Request and Create Data Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(request_id=\"\", action=\"\"):\n",
    "    url = 'https://services.sentinel-hub.com/batch/v1/process/'\n",
    "    if request_id:\n",
    "        url += f'{request_id}/'\n",
    "        if action:\n",
    "            url += f'{action}'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creating request\n",
    "response = oauth.request(\"POST\", generate_url(), headers=headers, json = payload).json()\n",
    "request_id = response[\"id\"]\n",
    "\n",
    "# Starting processing\n",
    "oauth.request(\"POST\", generate_url(request_id, 'start'))\n",
    "\n",
    "# Polling for completion\n",
    "response_status = \"\"\n",
    "while response_status not in ['DONE', 'FAILED']:\n",
    "    clear_output(True); print('Waiting upon completion...');\n",
    "    response_status = oauth.request(\"GET\", generate_url(request_id)).json()['status']\n",
    "    print(f\"Request {request_id} {response_status}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = oauth.request('GET', generate_url(request_id, 'tiles')).json()['member']\n",
    "costs = sum([t['cost'] for t in tiles])\n",
    "print(f'Processing Costs: {costs:.2f} Processing Units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bk = s3.Bucket(bucket_name)\n",
    "print(\"Data Cube Size: {:.2f} MiB\"\n",
    "      .format(sum([obj.size for obj in bk.objects.all().filter(Prefix=request_id)])/2**20)) # total size in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Save metadata to bucket\n",
    "bk.put_object(Key=request_id + '/userdata.json', Body=json.dumps({\n",
    "    'bands': output_bands,\n",
    "    'request_id': request_id,\n",
    "    'tiles': [tile['id'] for tile in tiles],\n",
    "    'time': avg_times    \n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Data Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "userdata_obj = bk.Object(f'{request_id}/userdata.json')\n",
    "file_stream = io.BytesIO()\n",
    "userdata_obj.download_fileobj(file_stream) # load userdata.json into file_stream\n",
    "userdata = json.loads(file_stream.getvalue())\n",
    "userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data cube into xarray Dataset\n",
    "dss = []\n",
    "for t in userdata['tiles']:\n",
    "    arrs = {b: xr.open_rasterio(f's3://{bucket_name}/{request_id}/{t}/{b}.tif') for b in userdata['bands']}\n",
    "    dss.append(xr.Dataset(arrs))\n",
    "ds = xr.combine_by_coords(dss)\n",
    "\n",
    "# Describe xarray Dataset with metadata\n",
    "ds = ds.rename({'band': 'time', 'y': 'lat', 'x': 'lon'})\n",
    "ds.coords['time'] = [np.datetime64(t) for t in userdata['time']]\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_index(val, src=(0,2**16-1), dst=(-1,+1)): \n",
    "    \"\"\"\n",
    "    Scale the given value from the scale of src to the scale of dst.\n",
    "    \"\"\"\n",
    "    return ((val - src[0]) / (src[1]-src[0])) * (dst[1]-dst[0]) + dst[0]\n",
    "\n",
    "scale_index(ds.isel(lat=2, lon=2).NDVI).plot.line('b-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "properties": {
   "description": "Process a data cube and access it from your AWS S3 bucket",
   "id": "a5d87f79-e944-4aa1-9210-8148819a8df6",
   "license": "MIT",
   "name": "Create & Access a Data Cube via EDC Mass Processing Service",
   "requirements": [
    "eurodatacube"
   ],
   "tags": [
    "EO Data",
    "Getting started",
    "Jupyter",
    "Mass Processing",
    "Sentinel Data",
    "Sentinel Hub"
   ],
   "tosAgree": true,
   "type": "Jupyter Notebook",
   "user_id": "0d6df427-8c09-41b9-abc9-64ce13a68125",
   "version": "0.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
