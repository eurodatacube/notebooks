{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e906857b",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f119a7d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T15:53:24.746753Z",
     "iopub.status.busy": "2021-06-03T15:53:24.746144Z",
     "iopub.status.idle": "2021-06-03T15:53:24.802227Z",
     "shell.execute_reply": "2021-06-03T15:53:24.802580Z"
    },
    "papermill": {
     "duration": 0.08332,
     "end_time": "2021-06-03T15:53:24.802779",
     "exception": false,
     "start_time": "2021-06-03T15:53:24.719459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "        function toggle(id) {\n",
       "            el = document.getElementById(id);\n",
       "            el.style.display = el.style.display === \"none\" ? \"block\" : \"none\";\n",
       "        }\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "This notebook is compatible with this base image version (user-0.24.5)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "---------\n",
       "\n",
       "The following environment variables are available:\n",
       "\n",
       "* `SH_CLIENT_ID`, `SH_INSTANCE_ID`, `SH_CLIENT_NAME`, `SH_CLIENT_SECRET`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from edc import check_compatibility\n",
    "check_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66f3cd-9975-45c1-91bd-d3804533cb0c",
   "metadata": {
    "papermill": {
     "duration": 0.028197,
     "end_time": "2021-06-03T15:53:24.854062",
     "exception": false,
     "start_time": "2021-06-03T15:53:24.825865",
     "status": "completed"
    },
    "tags": [
     "AIREO",
     "CAP"
    ]
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43180d-5d91-4f9d-93b9-8ad6854dfefd",
   "metadata": {
    "papermill": {
     "duration": 0.020798,
     "end_time": "2021-06-03T15:53:24.895596",
     "exception": false,
     "start_time": "2021-06-03T15:53:24.874798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The notebook demonstrates the use of <b> aireo_lib </b>, a python library created as a part of the [AIREO](https://aireo.net/) (Artificial Intelligence Ready Earth Observation training datasets) project. The project aims to make EO datasets easily accessible for the ML (Machine Learning) community. As such, AIREO specifications (shorthand specs) which define metadata elements to be included with the training dataset are proposed, supplemented by a best-practices document which suggests how to fill those metadata elements. Finally, the library takes all into account and implements specs, best-practices and offers an easy-to-use pythonic interface bridging the gap between EO and ML community.\n",
    "\n",
    "Therefore, this notebook is divided into two sections, one for the training dataset creator (usually from the EO community) and the other for its user (usually from the ML community). The structure of the notebook is the following:\n",
    "\n",
    "\n",
    "1) For Creator \n",
    "\n",
    "    - Create a [STAC](https://stacspec.org/) catalog object using the library\n",
    "    \n",
    "    - Populate metadata elements prescribed by the AIREO specs\n",
    "    \n",
    "    - Generate a STAC metadata directory using the library\n",
    "\n",
    "    - Check AIREO compliance level and metadata completeness\n",
    "\n",
    "   \n",
    "2) For User \n",
    "\n",
    "    - Create a training dataset object as defined in the library using only the STAC metadata\n",
    "    \n",
    "    - Get example instances from the object and other dataset variables like the number of instances, etc.\n",
    "    \n",
    "    - Use library's functions to plot the data\n",
    "    \n",
    "    - Investigate statistics using the library\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094b8e1-d3b2-4468-afc8-20fa1e44c084",
   "metadata": {
    "papermill": {
     "duration": 0.021219,
     "end_time": "2021-06-03T15:53:24.938299",
     "exception": false,
     "start_time": "2021-06-03T15:53:24.917080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### About the training dataset\n",
    "\n",
    "The CAP (Common Agricultural Policy) dataset, contains crop fields in Austria with different crop types. We have divided all of Austria in rectangular AOIs (Area if Interests) and downloaded Sentinel 2 images at 10 m resolution for each of those, they have been saved as geotiff files. The field shapes and the crop types have been converted to raster masks over these Sentinel 2 images, with each crop denoted by a different number, these are also stored as geotiffs. Only top 10 crop types which occupied almost 85% of the area are used. Hope this information will help you getting started and more can be found in various metadata elements below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b1f5d-3868-4b72-9343-92ff5e33d755",
   "metadata": {
    "papermill": {
     "duration": 0.021387,
     "end_time": "2021-06-03T15:53:24.980901",
     "exception": false,
     "start_time": "2021-06-03T15:53:24.959514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Creator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8ddc0-3f83-4a06-903e-20c1f4cd01aa",
   "metadata": {
    "papermill": {
     "duration": 0.021547,
     "end_time": "2021-06-03T15:53:25.023918",
     "exception": false,
     "start_time": "2021-06-03T15:53:25.002371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## AIREO STAC Catalog basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2d405-f227-4663-8e0d-a35976bc96e0",
   "metadata": {
    "papermill": {
     "duration": 0.021777,
     "end_time": "2021-06-03T15:53:25.066776",
     "exception": false,
     "start_time": "2021-06-03T15:53:25.044999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "The AIREO specs propose a hierarchical structure for STAC metadata. It is a two level structure where the dataset is represented by a collection of AOIs (Area Of Interests), hence, the dataset and AOI being the two levels.\n",
    "\n",
    "1. At the dataset level we have a dataset catalog whose metadata elements are the core elements proposed in the AIREO spec. In addition to it, the common metadata elements across each AOI are also at the dataset level, which we shall call root level henceforth. Here, for each data variable there is a separate json which is a STAC Item by definition and is named using the field_schema metadata element. Additionally, there is also a datasheet file in markdown format at the root level which contains human readable information about the key elements of the dataset.\n",
    "\n",
    "2. Each AOI has a separate folder within the root level. And in each AOI folder there is a STAC collection representing that AOI and additional json files for each data variable. The additional json files here too, are STAC Items and follow a similar naming convention to the ones at the root level. The assets for each AOI, i.e. the files containing actual data are also in the folder.\n",
    "\n",
    "The diagram below summarises this hierarchical structure:\n",
    "\n",
    "\n",
    "```\n",
    "Root level (dataset)\n",
    "│\n",
    "│   DatasetCatalog.json\n",
    "│   datasheet.md\n",
    "│   references_output1.json\n",
    "│   features_input1.json\n",
    "│   ...\n",
    "│\n",
    "│\n",
    "└───AOI 1\n",
    "│      1.json (AOI Collection)\n",
    "│      feature_input1.json\n",
    "│      reference_output1.json\n",
    "│      <reference_asset>\n",
    "│      <feature_asseet>\n",
    "│   \n",
    "│   \n",
    "└───AOI 2\n",
    "│      ...\n",
    "│   \n",
    "│\n",
    "└───AOI 3\n",
    "│      ...\n",
    "│   \n",
    "...     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcf458-590a-4f46-b488-e2f69ce87488",
   "metadata": {
    "papermill": {
     "duration": 0.020746,
     "end_time": "2021-06-03T15:53:25.108832",
     "exception": false,
     "start_time": "2021-06-03T15:53:25.088086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating a STAC catalog with aireo_lib\n",
    "\n",
    "The aireo_lib library makes it easier to generate the STAC metadata directory as defined above. Some of the useful functionalities in the library are:\n",
    "-  Define python dictionaries for metadata at the root level and use a simple function to add it to the STAC catalog. The library validates the data automatically when it is added.\n",
    "\n",
    "- Similarly, python dictionaries can be defined for each AOI and are also validated automatically.\n",
    "\n",
    "- Links and assets for all the json files are automatically generated.\n",
    "\n",
    "- Datasheet is also generated automatically.\n",
    "\n",
    "- The directory structure is created by the library and assets copied to their respective locations in the hierarchy.\n",
    "\n",
    "- Evaluating metadata completeness and compliance level.\n",
    "\n",
    "\n",
    "Follow the code and comments below to understand the steps needed to generate STAC metadata with the library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a72eaa",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d1cb2d-2977-41ca-894b-772052c2fcec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T15:53:25.155861Z",
     "iopub.status.busy": "2021-06-03T15:53:25.155273Z",
     "iopub.status.idle": "2021-06-03T15:53:25.206850Z",
     "shell.execute_reply": "2021-06-03T15:53:25.205955Z"
    },
    "papermill": {
     "duration": 0.076716,
     "end_time": "2021-06-03T15:53:25.207059",
     "exception": true,
     "start_time": "2021-06-03T15:53:25.130343",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aireo_lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-118af8f203d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0maireo_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mosgeo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'aireo_lib'"
     ]
    }
   ],
   "source": [
    "import aireo_lib.core\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely import geometry\n",
    "import shutil\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e815fd-e92b-48fe-b9ef-ff30174b282a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating an empty STAC Catalog object to add metadata to\n",
    "\n",
    "new_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf964cb-84a7-49bf-bad6-d5fee6fc09a9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a list of AOIs in the TDS\n",
    "\n",
    "reference_path = '../dataset/cap_tiff_mask'\n",
    "aoi_ids = [int(i.replace('.tif','').replace('patch_mask_','')) for i in os.listdir(reference_path) if '.tif' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8e8bb-0d9a-45bf-bdb8-c91796862e74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function to get train, validation and test splits of the dataset which can be recorded in the root Catalog\n",
    "def get_train_val_test_dict():\n",
    "    patches = [int(i.replace('patch_mask_','').replace('.tif','')) for i in os.listdir('../dataset/cap_tiff_mask') if 'mask' in i]\n",
    "    patches.sort()\n",
    "    # 15% of the AOIs for test and validation split each and the remaning 70% for training\n",
    "    dim = int(len(patches)*0.15)\n",
    "    splits = {}\n",
    "    splits['test_aois'] = patches[:dim]\n",
    "    splits['val_aois'] = patches[-dim:]\n",
    "    splits['train_aois'] = patches[dim:-dim]\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc70237-bef4-4389-8c69-fa80a63ae7c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating root Catalog metadata dictionary. These are the CoreElements of AIREO spec.\n",
    "\n",
    "tds_root_core_metadata_d = {}\n",
    "tds_root_core_metadata_d['aireo_version'] = \"0.0.1-alpha.1\"\n",
    "tds_root_core_metadata_d['title'] = \"Fields with crop types from Austria, 2019\"\n",
    "tds_root_core_metadata_d['description'] = \"The dataset contains the fields in Austria (as recorded in 2019) with their shapes stored as polygons and the crop type that was grown in the fields. Accompanied with the dataset are satellite images from sentinel 2 with fields as masks over the image. The masks of different crop types have a different number as label.\"\n",
    "tds_root_core_metadata_d['created'] = None\n",
    "tds_root_core_metadata_d['license_url_list'] = ['https://creativecommons.org/licenses/by/4.0/deed.de, https://creativecommons.org/licenses/by-sa/3.0/igo/legalcode']\n",
    "tds_root_core_metadata_d['license'] = \"Various (CC-BY-4.0, Creative Commons CC BY-SA 3.0 IGO)\"\n",
    "tds_root_core_metadata_d[\"providers_name\"]= \"[Agricultural Market Austria, Sentinel Hub, AIREO]\"\n",
    "tds_root_core_metadata_d[\"providers_description\"] = \"Agricultural Market Austria publsihed the data on field shapes and crop types grown in them. AIREO network downloaded the corresponding satellite imagery for the fields and created masks. AIREO network also created this metadata.\"\n",
    "tds_root_core_metadata_d[\"providers_role\"] = {'Sentinel Hub': [\"licensor\", \"producer\"], 'AIREO':[\"producer\", \"processor\" , \"host\"],'Agricultural Market Austria':[\"producer\", \"processor\" ]}\n",
    "tds_root_core_metadata_d[\"providers_url\"]= {'Agricultural Market Austria':'https://www.ama.at/Intro.', 'Sentinel Hub': 'https://www.sentinel-hub.com/', \n",
    "                        'AIREO': 'https://aireo.net/'}                         \n",
    "tds_root_core_metadata_d['id'] =  \"970460aa-7835-11eb-9439-0242ac130002\"\n",
    "tds_root_core_metadata_d['type'] = \"Collection\"\n",
    "tds_root_core_metadata_d['stac_version'] = '1.0.0-beta.2'\n",
    "tds_root_core_metadata_d['provenance'] = 'The shapes of fields and the crop type were taken from the data provided by Agricultural Market Austria (see providers) and the accompanying satellite images were provided by Sentinel Hub (see links in providers), as Sentinel 2 images.'\n",
    "tds_root_core_metadata_d['purpose'] = \"The dataset has sentinel 2 images with a mask of fields with 10 different crop types. Each crop type is denoted by a unique identifier. The main prupose for this creating this dataset was to serve as a pilot use case for AIREO specifications. But it can also be used for crop type indentification from satellite images or parcel identification.\"\n",
    "tds_root_core_metadata_d['tasks'] =  ['Semantic Segmentation']\n",
    "tds_root_core_metadata_d['collection_mechanism'] = \"The way the underlying data about fields was collected hasn't been mentioned in the source of that data. The satellite images were acquired by optical sensors aboard Sentinel 2 satellite.\"\n",
    "tds_root_core_metadata_d['data_preprocessing'] = 'The data was collated using two sources of data: field and crop type from Agricultural Market Austria and Sentinel 2 images from sentinel hub. The process of combining these two datasets by downloading satellite image and overlaying it with a mask of different crop types and fields was done through eo-learn library. \\\n",
    "Only satellite images with cloud cover less than 1% were considered and the dates for the images were chosen to be in late 2019. Also, only the top 10 crop types occupying most area (85% of the total area) were considered from 214 present in the original dataset.'\n",
    "tds_root_core_metadata_d['funding_info'] = \"The AIREO project is funded by ESA, the collection of data on fields and crop types were \\\n",
    "are funded by Agricultural Market Austria and the satellite imagery used is through funds from ESA's Sentinel programme.\"\n",
    "tds_root_core_metadata_d['field_schema'] = {'features': {'input1': ['georeferenced_eo_image']}, 'references': {'output1': ['reference_data']}}\n",
    "tds_root_core_metadata_d['example_definition'] = \"An example instance for training a machine learning model would be one satellite image with various bands as predicitve features and the mask as reference data. This can be used for predicting various fields with crop types or for field parcel identification.\"\n",
    "tds_root_core_metadata_d['example_window_size'] = 256\n",
    "tds_root_core_metadata_d['example_stride'] = 26\n",
    "                                                 \n",
    "tds_root_core_metadata_d['data_completeness'] = \"The data has 10 crop types with fields only from Austria. \\\n",
    "The names of these crops do not follow any standard and are in German and these might not be the only crop types available. There is no information whether these are all the fields in Austria or there are more not included in the dataset. The scenario where multiple crops are grown in a field over the year is also not addressed. There is no unique time for when the crop type for each field was ascertained during 2019.\"\n",
    "tds_root_core_metadata_d['data_split'] = f\"The  split  should  reflect  a  similar  distribution  of  field  types as in the whole dataset.  It  is  not  necessary  to  match \\\n",
    "distributions of all these 10 crop types but only a few ones occupying most area. \\n {get_train_val_test_dict()}\"\n",
    "tds_root_core_metadata_d['data_sharing'] = \"The dataset will be shared on Euro Data Cube (EDC) and can be accessed through jupyter notebooks on EDC.\"\n",
    "tds_root_core_metadata_d['compliance_level'] = 'level 1'\n",
    "tds_root_core_metadata_d['links'] =  []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a0d06-6127-4530-96fc-b432397c2699",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Common metadata dictionary for predictive feature variable\n",
    "\n",
    "g_feature_metadata_d = {}\n",
    "g_feature_metadata_d['type'] = \"Feature\"\n",
    "g_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n",
    "g_feature_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\n",
    "g_feature_metadata_d['id'] = f'common_predictive_feature_metadata'\n",
    "g_feature_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n",
    "with open('../dataset/austria.geojson','r') as austria:\n",
    "    shape = json.load(austria)\n",
    "# The geometry accepts pydantic Geometry type, which is a dictionary. See pydantic's documentation for more info\n",
    "g_feature_metadata_d['geometry'] = shape['features'][0]['geometry']\n",
    "geom = np.array(shape['features'][0]['geometry']['coordinates'][0])\n",
    "xs = geom[:,0]\n",
    "ys = geom[:,1]\n",
    "g_feature_metadata_d['bbox'] = [min(xs),min(ys), max(xs), max(ys)]\n",
    "g_feature_metadata_d['properties'] = {}\n",
    "g_feature_metadata_d[\"properties\"]['parent_identifier'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n",
    "g_feature_metadata_d[\"properties\"]['product_type']  = \"Null\"\n",
    "g_feature_metadata_d[\"properties\"]['processing_level'] = 1.0\n",
    "g_feature_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\n",
    "g_feature_metadata_d[\"properties\"]['sensor_type'] = \"OPTICAL\"\n",
    "g_feature_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\n",
    "g_feature_metadata_d[\"properties\"]['gsd'] = 10\n",
    "g_feature_metadata_d['properties']['datetime'] = \"2019\"\n",
    "g_feature_metadata_d['properties']['acquisition_date'] = \"2019\"\n",
    "g_feature_metadata_d[\"properties\"]['identifier'] = f'common_predictive_feature_metadata'\n",
    "g_feature_metadata_d['links'] = []\n",
    "g_feature_metadata_d[\"assets\"] =  {}\n",
    "feature_metadata_d = {}\n",
    "feature_metadata_d['input1'] = g_feature_metadata_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fda05-da03-48c3-97d1-29044ca2a316",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Common metadata dictionary for reference data variable\n",
    "\n",
    "g_ref_data_metadata_d = {}\n",
    "\n",
    "g_ref_data_metadata_d['id'] = f'common_reference_metadata'\n",
    "g_ref_data_metadata_d['type'] = \"Feature\"\n",
    "g_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n",
    "g_ref_data_metadata_d['stac_extensions'] = [\"reference_data\"]\n",
    "g_ref_data_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n",
    "with open('../dataset/austria.geojson','r') as austria:\n",
    "    shape = json.load(austria)\n",
    "# The geometry accepts pydantic Geometry type, which is a dictionary. See pydantic's documentation for more info\n",
    "g_ref_data_metadata_d['geometry'] = shape['features'][0]['geometry']\n",
    "geom = np.array(shape['features'][0]['geometry']['coordinates'][0])\n",
    "xs = geom[:,0]\n",
    "ys = geom[:,1]\n",
    "g_ref_data_metadata_d['bbox'] = [min(xs),min(ys), max(xs), max(ys)]\n",
    "g_ref_data_metadata_d['properties'] = {}\n",
    "g_ref_data_metadata_d[\"properties\"]['name'] = \"Reference metadata\"\n",
    "g_ref_data_metadata_d['properties']['description'] = \"The reference data consists of masks of different field types as given in the 2019 dataset by Agricultural Market Austria. Originally, it was  meant for processing of CAP subsidies but can be used for segmentation in the current form.\"\n",
    "g_ref_data_metadata_d['properties']['type'] = \"Raster\"\n",
    "g_ref_data_metadata_d['properties']['task'] = \"Semantic Segmentation\"\n",
    "g_ref_data_metadata_d['properties']['classes'] = [{'ALM FORAGE AREA': 990, 'MOWING MEADOW / PASTURE THREE AND MORE USES': 717,\n",
    "                   'WINTER SOFT WHEAT': 138, 'MOWING MEADOW / PASTURE TWO USES': 716,\n",
    "                   'GRAIN CORN': 105, 'WINTER BARLEY': 110, 'SILO CORN': 109, 'PERMANENT PASTURE': 715,\n",
    "                   'SOYBEANS': 308, 'HAT WILLOW': 707, 'BACKGROUND': 0}]\n",
    "g_ref_data_metadata_d['properties']['overviews'] = [\"They are two overviews total area covered by each field type anda and total number of each field types. Total area covered in hectares ,\\\n",
    "    990: 922491.316277, 717: 495099.341968, 138 : 245556.123391, 716: 212395.276761, 105: 196645.398665, 110: 100947.839432,\\\n",
    "    109: 85574.511958, 715: 77478.090196, 308: 69023.96593, 707: 62440.674009 \\\n",
    "    total number of fields with the crop type, 717: 403540, 716: 315165, 990: 237072, 771: 120610, 351: 120479, 138: 120310, 105: 112095, 707: 110882, 715: 89674,\\\n",
    "    901: 81586\"]\n",
    "g_ref_data_metadata_d['properties']['collection_methods'] = \"The reference data was collected by Agricultural Market Austria for the year 2019 for Common Agriculture Practices for EU to process agriculture subsidies, etc. The exact method for ground surveys was not clearly documented and the only info available is that \\\"all field uses were recorded by the applicants\\\".\"\n",
    "g_ref_data_metadata_d['properties']['data_preprocessing'] = \"The polygons in the original reference data were converted into rasters overlayed on satellite image of 10m resoltuion. \\\n",
    "Only the top 10 crop types occupying most area (85% of total) were used and others were filtered out and labelled as background.\"\n",
    "g_ref_data_metadata_d['properties']['CRS'] = 'EPSG:32631'\n",
    "g_ref_data_metadata_d['properties']['time_range'] = '2019'\n",
    "g_ref_data_metadata_d[\"properties\"]['value'] = 0\n",
    "g_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\n",
    "g_ref_data_metadata_d['links'] = []\n",
    "g_ref_data_metadata_d[\"assets\"] = {}\n",
    "\n",
    "ref_metadata_d = {}\n",
    "ref_metadata_d['output1'] = g_ref_data_metadata_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1a718-e3d2-4d69-ac3e-64ae22ec1de9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add TDS root Catalog and common Item metadata to the catalog object. \n",
    "# Note, that it returns True, if the data isn't validated it will return False\n",
    "\n",
    "new_tds_ctl_o.add_tds_root_metadata(tds_root_core_metadata_d, feature_metadata_d, ref_metadata_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1dd152-d021-4138-be5e-e37e9c83ab73",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding metadata for each AOI\n",
    "\n",
    "for aoi_id in tqdm(aoi_ids[:7]):\n",
    "        \n",
    "    # Dictionary for each AOI collection metadata\n",
    "    aoi_metadata_d = {}\n",
    "    aoi_metadata_d['type'] = \"Collection\"\n",
    "    aoi_metadata_d[\"id\"] = f\"{aoi_id}\"\n",
    "    aoi_metadata_d['stac_version'] = '1.0.0-beta.2'\n",
    "    aoi_metadata_d['title'] = f\"{aoi_id} Collection\"\n",
    "    aoi_metadata_d['description'] = \"Each AOI contains satellite images with crop masks.\"\n",
    "    aoi_metadata_d[\"license\"] = \"Various (CC-BY-4.0, Creative Commons CC BY-SA 3.0 IGO)\"\n",
    "    mask = gdal.Open(os.path.join(reference_path, f'patch_mask_{aoi_id}.tif'))\n",
    "    geoTransform = mask.GetGeoTransform()\n",
    "    minx = geoTransform[0]\n",
    "    maxy = geoTransform[3]\n",
    "    maxx = minx + geoTransform[1] * mask.RasterXSize\n",
    "    miny = maxy + geoTransform[5] * mask.RasterYSize\n",
    "    aoi_metadata_d[\"bbox\"]= [minx, miny, maxx, maxy]\n",
    "    # The geometry accepts pydantic Geometry type, which is a dictionary. See pydantic's documentation for more info\n",
    "    aoi_metadata_d['geometry'] = geometry.mapping(geometry.box(*aoi_metadata_d[\"bbox\"]))\n",
    "    aoi_metadata_d[\"extent\"] = {\"spatial\" : {\"bbox\":[[minx, miny, maxx, maxy]]}, \n",
    "                      \"temporal\": {\"interval\":[['2019']]}}\n",
    "    aoi_metadata_d['time_range'] = '2019'\n",
    "    aoi_metadata_d['links'] = []\n",
    "    aoi_metadata_d[\"assets\"] = {}\n",
    "    \n",
    "    \n",
    "    # Dictionary for each AOI's predictive feature variable metadata\n",
    "    aoi_feature_metadata_d = {}\n",
    "    aoi_feature_metadata_d['id'] = f'predictive_feature_metadata_AOI_{aoi_id}'\n",
    "    aoi_feature_metadata_d['type'] = \"Feature\"\n",
    "    aoi_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n",
    "    aoi_feature_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\n",
    "    aoi_feature_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n",
    "    aoi_feature_metadata_d['bbox'] = aoi_metadata_d[\"bbox\"]\n",
    "    aoi_feature_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n",
    "    aoi_feature_metadata_d['properties'] = {}\n",
    "    aoi_feature_metadata_d[\"properties\"]['parent_identifier'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n",
    "    aoi_feature_metadata_d[\"properties\"]['product_type']  = \"Null\"\n",
    "    aoi_feature_metadata_d[\"properties\"]['processing_level'] = 1.0\n",
    "    aoi_feature_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\n",
    "    aoi_feature_metadata_d[\"properties\"]['sensor_type'] = \"OPTICAL\"\n",
    "    aoi_feature_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\n",
    "    aoi_feature_metadata_d[\"properties\"]['gsd'] = 10\n",
    "    aoi_feature_metadata_d[\"properties\"]['CRS'] = 'EPSG:32631'\n",
    "    aoi_feature_metadata_d[\"properties\"]['identifier'] = str(aoi_id)\n",
    "    aoi_feature_metadata_d[\"properties\"]['acquisition_date'] = '2019'\n",
    "    aoi_feature_metadata_d[\"properties\"]['datetime'] = \"2020-03-09T14:53:23.262208+00:00\"\n",
    "    aoi_feature_metadata_d['links'] = []  \n",
    "    aoi_feature_metadata_d[\"assets\"] = {}\n",
    "\n",
    "    aoi_feature_d = {}\n",
    "    aoi_feature_d['input1'] = aoi_feature_metadata_d\n",
    "    \n",
    "    # Dictionary for each AOI's reference variable metadata\n",
    "    aoi_ref_data_metadata_d = {}\n",
    "    aoi_ref_data_metadata_d['type'] = \"Feature\"\n",
    "    aoi_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n",
    "    aoi_ref_data_metadata_d['stac_extensions'] = [\"reference_data\"]\n",
    "    aoi_ref_data_metadata_d['id'] = f'reference_metadata_AOI_{aoi_id}'\n",
    "    aoi_ref_data_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n",
    "    aoi_ref_data_metadata_d[\"bbox\"]= aoi_metadata_d[\"bbox\"]\n",
    "    aoi_ref_data_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n",
    "    aoi_ref_data_metadata_d[\"properties\"] = {}\n",
    "    aoi_ref_data_metadata_d['properties']['classes'] = [{'ALM FORAGE AREA': 990, 'MOWING MEADOW / PASTURE THREE AND MORE USES': 717,\n",
    "                       'WINTER SOFT WHEAT': 138, 'MOWING MEADOW / PASTURE TWO USES': 716,\n",
    "                       'GRAIN CORN': 105, 'WINTER BARLEY': 110, 'SILO CORN': 109, 'PERMANENT PASTURE': 715,\n",
    "                       'SOYBEANS': 308, 'HAT WILLOW': 707, 'BACKGROUND': 0}]\n",
    "    aoi_ref_data_metadata_d[\"properties\"]['name'] = str(aoi_id)+ \" Reference metadata\"\n",
    "    aoi_ref_data_metadata_d['properties']['description'] = \"The reference data consists of masks of different field types as given in the 2019 dataset by Agricultural Market Austria. Originally, it was  meant for processing of CAP subsidies but can be used for segmentation in the current form.\"\n",
    "    aoi_ref_data_metadata_d['properties']['type'] = \"Raster\"\n",
    "    aoi_ref_data_metadata_d['properties']['task'] = \"Semantic Segmentation\"\n",
    "    aoi_ref_data_metadata_d['properties']['CRS'] = 'EPSG:32631'\n",
    "    aoi_ref_data_metadata_d['properties']['time_range'] = '2019'\n",
    "    aoi_ref_data_metadata_d[\"properties\"]['value'] = 0\n",
    "    aoi_ref_data_metadata_d['properties'][\"orientation\"]= \"null\"\n",
    "    aoi_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\n",
    "    aoi_ref_data_metadata_d['links'] = []\n",
    "    aoi_ref_data_metadata_d[\"assets\"] = {}\n",
    "    aoi_ref_d = {}\n",
    "    aoi_ref_d['output1'] = aoi_ref_data_metadata_d\n",
    "    \n",
    "    # Defining path to assets to copy over to AOI directory\n",
    "    aoi_ref_data_asset_path_d = {'output1':os.path.join('/home/jovyan/s3/CAP/dataset/cap_tiff_mask', f'patch_mask_{aoi_id}.tif')}\n",
    "    aoi_feature_asset_path_d = {'input1':os.path.join('/home/jovyan/s3/CAP/dataset/cap_tiff', f'patch_{aoi_id}.tif')}\n",
    "    \n",
    "    # Add each AOI's metadata to catalog object. Note, each AOI is also validated and returns True.\n",
    "    print(new_tds_ctl_o.add_aoi_metadata(aoi_metadata_d=aoi_metadata_d,\n",
    "                                   aoi_feature_metadata_d=aoi_feature_d,\n",
    "                                   aoi_ref_data_metadata_d=aoi_ref_d,\n",
    "                                   aoi_feature_asset_path_d=aoi_feature_asset_path_d,\n",
    "                                   aoi_ref_data_asset_path_d=aoi_ref_data_asset_path_d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c337f-511d-48a9-997b-36fba01fc802",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('../cap_stac_generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85c9b9-ca10-433a-8330-0cddc92b369c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing the STAC metadata. The directory along with its structure is generated, with correct links and assets defined. \n",
    "#A datasheet is also generated\n",
    "\n",
    "catalog_fn_w_path = '/home/jovyan/s3/CAP/cap_stac_generated/TDS.json'\n",
    "new_tds_ctl_o.write_TDS_STAC_Catalog(catalog_fn_w_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711274a-e879-4098-9a6f-fe4d1ef8bf18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Checking AIREO compliance level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949448b-909b-4dd6-ac0b-4c2c3294109a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checks the compliance level of the metadata as defined in AIREO spec.\n",
    "\n",
    "catalog_fn_w_path = '/home/jovyan/s3/CAP/cap_stac_generated/TDS.json'\n",
    "new_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog.from_TDSCatalog(catalog_fn_w_path)\n",
    "new_tds_ctl_o.compute_compliance_level()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6575b4f-3518-4d14-aaa5-ea27e44b2452",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Checking metadata completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ec332-ed57-4991-a720-5cee33f39b5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_tds_ctl_o.report_metadata_completeness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d3b0b-3d81-4873-b849-93987b6b1e8c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Defining AOI class\n",
    "\n",
    "For enabling many other functionalities of the library the dataset creator needs to create an AOI class which defines how the asset files are loaded, can return an example and length of the dataset. The blueprint is given in the library by the AOIDataset class which this class should inherit. In the future, it is planned to automate the creation of the AOI class also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96daf59-3406-4702-b45e-93672db43316",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#should inherit AOIDataset\n",
    "\n",
    "from aireo_lib.core import AOIDataset\n",
    "\n",
    "class AOIDatasetCAP(AOIDataset):\n",
    "\n",
    "    def __init__(self, AOI_STAC_collection, TDS_STAC_catalog):\n",
    "\n",
    "        self.AOI_STAC_collection = AOI_STAC_collection\n",
    "        self.TDS_STAC_catalog = TDS_STAC_catalog\n",
    "        self.stride = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_stride']\n",
    "        self.window_size = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_window_size']\n",
    "        \n",
    "\n",
    "        _first = True\n",
    "        \n",
    "        for eo_feature in self.AOI_STAC_collection.aoi_all_field_metadata.features:\n",
    "            aoi_feature_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.features[eo_feature].data_asset_w_path\n",
    "            self.feature_var_name = 'features_'+eo_feature\n",
    "            if _first:\n",
    "                self.data = rioxarray.open_rasterio(aoi_feature_asset_path_d).to_dataset(name=self.feature_var_name) \n",
    "                _first = False\n",
    "            else:\n",
    "                tmp = rioxarray.open_rasterio(aoi_feature_asset_path_d)\n",
    "                self.data[self.feature_var_name] = tmp\n",
    "                self.data[self.feature_var_name].values = tmp.values\n",
    "                \n",
    "        aoi_name = aoi_feature_asset_path_d.split('/')[-1].replace('patch_','').replace('.tif','')\n",
    "        for reference_data in self.AOI_STAC_collection.aoi_all_field_metadata.references:\n",
    "            aoi_ref_data_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.references[reference_data].data_asset_w_path\n",
    "            self.ref_var_name = 'references_'+reference_data\n",
    "            if _first:\n",
    "                self.data = rioxarray.open_rasterio(aoi_ref_data_asset_path_d).to_dataset(name = self.ref_var_name)\n",
    "                _first = False\n",
    "            else:\n",
    "                tmp = rioxarray.open_rasterio(aoi_ref_data_asset_path_d).rename({'band':'mask'})\n",
    "                self.data[self.ref_var_name] = tmp\n",
    "                self.data[self.ref_var_name].values = tmp.values\n",
    "                self.data.attrs = tmp.attrs\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "       \n",
    "        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride)\n",
    "        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride)\n",
    "        x1 = self.stride * int(index % along_x)\n",
    "        y1 = self.stride * int(index / along_y)\n",
    "        x2 = x1 + self.window_size\n",
    "        y2 = y1 + self.window_size\n",
    "        \n",
    "        #store feature and reference data in same xarray, name the axes\n",
    "        ds = self.data.isel(band=[0,1,2,3], mask=[0], x=slice(x1,x2), y=slice(y1, y2))        \n",
    "        return ds\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride) + 1\n",
    "        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride) + 1\n",
    "        return along_x * along_y\n",
    "    \n",
    "    def get_length(self):\n",
    "        return self.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381f1c9-1890-4586-a9b2-7afd2c8655f5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Dataset user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eff258-3cfa-43e8-8cf5-09475753c676",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The user of the dataset can access most of what is offered by the dataset using just its STAC catalog. All he/she needs to do is create a dataset object by passing to it the path to the STAC catalog at the root level. The library automatically reads in all the metadata and loads the assets into the dataset object. Some of the functionalities that a dataset object offers through aireo_lib are:\n",
    "\n",
    "- Can access an example instance from the dataset which serves as an input-output pair for a Machine Learning algorithm.\n",
    "\n",
    "- Xarrays are used to store data and give examples.\n",
    "\n",
    "- Dataset can also return each AOI independently\n",
    "\n",
    "- Offer basic plotting functions for each variable in the dataset and AOI.\n",
    "\n",
    "- Some statistics can also be calculated at both the AOI level and whole dataset level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dda67e-870f-411e-9e33-0a110fcaea8c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Parsing the dataset by creating a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884a653-139d-42ef-a212-b00ab3fdaf1b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aireo_lib.core import EOTrainingDataset\n",
    "\n",
    "cap_tds_ctl_fn = Path('/home/jovyan/s3/CAP/cap_stac_generated/TDS.json')\n",
    "\n",
    "eo_tds_obj = EOTrainingDataset(cap_tds_ctl_fn, AOIDatasetCAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f5aee-d499-43f9-b7c3-846364e1c904",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the number of instances/examples in the dataset\n",
    "\n",
    "len(eo_tds_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f1c96-4414-4a9a-bc74-db00653692cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing an example through index\n",
    "\n",
    "eo_tds_obj[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e8784-f4c8-48ee-9e74-16e3b38599fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing one variable of the instance\n",
    "\n",
    "eo_tds_obj[-5]['references_output1'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb75ede-774d-481f-a384-11febbb9b579",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a subset of examples\n",
    "\n",
    "eo_tds_obj.get_subset([19,1121, 2000, 2345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b516635-04e5-4764-a189-2cbd74f5ed95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access each AOI independently\n",
    "\n",
    "aoi_objs = eo_tds_obj.get_aoi_datasets()\n",
    "len(aoi_objs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae80304-2833-4e0e-9bcb-7ee4c18389e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Plotting functions in aireo_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd8181-1fa2-4c18-9428-46d438f9a21a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aireo_lib.plotting import EOTDSPlot as aireo_viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b2c5e-a667-4474-a9b8-f0ba756f30ee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic plot of all the variables in the dataset, returns a dict of matplotlib figures\n",
    "\n",
    "plot_d = aireo_viz.plot_example(EOTDS=eo_tds_obj, \n",
    "                       ex_index=-50, \n",
    "                       field_names=['features_input1', 'references_output1'])\n",
    "plot_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e8002-3ed8-45c5-a88c-415c8ae6fe21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a0072-c063-423c-badd-276bea967f47",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_d['references_output1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd9363e-e70a-4df7-b42b-e9532313c4f4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_d['features_input1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b194360-07e6-44de-98dd-83293a8cb7d4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoi_obj = eo_tds_obj.get_aoi_dataset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17134477-bc50-4ee8-a75d-c9387e43e356",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic plot of all the variables in an AOI, returns a dict of matplotlib figures\n",
    "\n",
    "aoi_plots_d = aireo_viz.plot_aoi_dataset(aoi_obj)\n",
    "aoi_plots_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb19e44-067c-44af-924d-49be3de09ce2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoi_plots_d['references_output1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63bded-ccec-40b3-bdb5-74d7ad35890c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoi_plots_d['features_input1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aadd3a6-094f-4070-aa70-f51fabb66012",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting different AOIs on the map of the world\n",
    "\n",
    "aireo_viz.map_aois(eo_tds_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4725f24-6f57-45d0-bb63-5e48dc653fa3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Statistics functions in aireo_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f88ad-c7f8-438c-a303-a2a731b7e8c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aireo_lib.statistics import EOTDSStatistics as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57842d0e-fc15-421f-b2cc-b75a2747800c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Common reference data statistics llike number of samples of each class in the whole dataset and each AOI\n",
    "\n",
    "stats.reference_data_statistics(eo_tds_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1adffc-8494-467b-92b1-dce33214976b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Common feature data statistics like mean, standard deviation, min and max for each channel in each AOI\n",
    "\n",
    "stats.feature_data_statistics(eo_tds_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6acfd-60f1-4856-80cf-046706d89496",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats.dataset_statistics(eo_tds_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e8b40-c6e4-4da5-b9cf-c8359b525709",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metadata completeness statistics also included\n",
    "\n",
    "stats.EOTDSStatistics.metadata_statistics(eo_tds_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a480ff-b05e-4d6b-8c73-7a27451e5b19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## ML model\n",
    "\n",
    "\n",
    "We try to demonstrate here how the library interfaces with existing ML libraries. This is an over simplistic implementation of resnet50 from pytorch to show this functionality of our library. We train the model for a few epochs with a few instances from our dataset object. The choices made here like loss function, optimizer, training indexes, etc. are only meant for demonstration and are in no way recommended and do not claim to be sensible choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b727501-fd89-45a2-b5d5-2d78167d8330",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea116e78-e047-4da5-acf0-df667d65c4b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the model object from torchvision\n",
    "\n",
    "model = torchvision.models.segmentation.fcn_resnet50(pretrained=False, progress=True, num_classes=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a27d43-1c59-4c2e-82d1-4c7191fbc655",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a loss function and optimizer\n",
    "\n",
    "def loss_fn(pred, truth):\n",
    "    pred = np.amax(pred.detach().numpy(),1)\n",
    "    return torch.tensor(sum(abs(pred-truth).flatten()), requires_grad=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c54de-8262-4216-97ba-3474d36e89cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating a few training instances from the dataset object\n",
    "\n",
    "import random\n",
    "train_indexes = random.choices(list(range(0, len(eo_tds_obj))),k=10)\n",
    "train_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cedbb-7975-4a98-bf78-1c50e40bbcaf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training the model for a few epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(4):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    total_loss = 0\n",
    "    for train_idx in train_indexes:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Getting one training instance from the dataset object\n",
    "        instance = eo_tds_obj[train_idx]\n",
    "        \n",
    "        # As resnet50 accepts only 3-D inputs we use only the first three bands of our satellite image\n",
    "        train_input = torch.tensor(np.expand_dims(instance.features_input1.values[:3,:,:], axis=0))\n",
    "        \n",
    "        # Reference data becomes label for training\n",
    "        train_labels = instance.references_output1.values\n",
    "        \n",
    "        output = model.forward(train_input)\n",
    "        loss = loss_fn(output['out'], train_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "    print('Total Running Loss:', loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDC-GPU 0.24.5 (Python3)",
   "language": "python",
   "name": "edc-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.849969,
   "end_time": "2021-06-03T15:53:25.512823",
   "environment_variables": {},
   "exception": true,
   "input_path": "/tmp/tmpnc6yoq4t",
   "output_path": "/tmp/notebook_output.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T15:53:23.662854",
   "version": "2.3.3"
  },
  "properties": {
   "authors": [
    {
     "id": "a7f80638-e89a-4349-9cc7-7ed6ec2d79b7",
     "name": "manuel.fernandez@nuigalway.ie"
    }
   ],
   "description": "Use of aireo_lib library as part of AIREO project",
   "id": "03a138eb-3fde-4f25-b3f7-ce62472e524e",
   "license": null,
   "name": "AIREO pilot dataset - CAP",
   "requirements": [
    "eurodatacube"
   ],
   "tags": [
    "EO Data",
    "Getting started",
    "Jupyter",
    "Machine Learning",
    "Sentinel Data"
   ],
   "tosAgree": true,
   "type": "Jupyter Notebook",
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}